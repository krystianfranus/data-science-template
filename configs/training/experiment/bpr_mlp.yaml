# @package _global_

defaults:
  - override /datamodule: bpr
  - override /model: bpr_mlp

datamodule:
  batch_size: 8192
  num_workers: 8
  pin_memory: true

model:
  n_factors: 8
  n_layers: 4
  dropout: 0.5
  lr1: 0.0001
  lr2: 0.00001
  weight_decay: 0.01

trainer:
  accelerator: "gpu"
  max_epochs: 50
